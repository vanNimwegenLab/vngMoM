---
title: "Demo script for mother machine data analysed with MoMA"
author: Thomas Julou
output: html_document
---

Define general variables:

```{r variables, include=FALSE}
dt <- 3             # frame intervall (min)
dl <- 0.065         # pixel size (µm)
vertical_cutoff <- 4 / dl   # after it touched this coordinate a cell is discarded 
                    # (4um, NB E. coli is ca. 2um )

# directory of the current project
# data files are expected to be found inside `./data`
proj_path <- "~/Documents/Biozentrum/Projects/vngWetLabR/mother_machine/example/"
# directory with shared scripts
r_scripts_path <- c("~/Documents/Biozentrum/Projects/vngWetLabR/mother_machine",
                  "~/Documents/Biozentrum/Projects/vngWetLabR/ggplot")
perl_scripts_path <- "~/Documents/Biozentrum/Projects/vngWetLabR/mother_machine"

# preprocessed data files (produced by perl scripts) are named and saved by applying
# `data2preproc` to their path (e.g. reproduce `data` inner structure inside `preproc`):
data2preproc_dir <- function(.f) 
  # replace ./data with ./preproc
  dirname(.f) %>% sub('/data/*', '/preproc/', .)
data2preproc_file <- function(.f)
  # append _preproc.txt to the filename
  basename(.f) %>% file_path_sans_ext %>% paste0("_preproc.txt")
data2preproc <- function(.path)
  file.path(data2preproc_dir(.path), data2preproc_file(.path))

```

Define experimental conditions and the corresponding data (see ReadMe.md):

```{r}
myconditions <- list(
  list(condition='lac_lowillum', duration=1440, medium='lactose',
       paths=c("./data/20160318_pos0")) #,
  # list(condition='switch_4h', 
  #      duration=c(360, 240, 240, 240, 240, 240),
  #      medium=c('glucose', 'lactose', 'glucose', 'lactose', 'glucose', 'lactose'),
  #      paths=c("./data/20160318_pos1", "./data/20160318_pos2"))
)

```


Setup the working environment:

```{r settings}
# define global settings for knitr
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE) # , include=FALSE

# set working environment (load all shared R scripts)
invisible(sapply(
  list.files(r_scripts_path, pattern="\\.[Rr]$", full.names=TRUE, ignore.case=TRUE), 
  source, .GlobalEnv))

setwd(proj_path)
dir.create("qlogs", showWarnings=FALSE) # create a directory to store logs from the queue

# set a parallel environment to run multidplyr
library(multidplyr)
numCores <- min(30, parallel::detectCores()-1) # do not use more than 30 cores
mycluster <- create_cluster(numCores)
for (.l in mylibs) { mycluster %>% cluster_library(.l) } # load all libraries on each core

```

Load all frames in a dataframe:

- This step calls a perl script to analyze MoMA's output (see ReadMe.md). 
  + If all files have already been processed, data will be loaded in a dataframe
  + otherwise, files to be analyze will be submitted to the cluster's queue and an error will be returned; you can check the state of the queue using the function printed in the error message
  + to force the preprocessing to be run again for all files, use .force=TRUE in `process_moma_data`.
- If you use `myconditions` appropriately, you should not need to call this loading step more than once per project.
- The specific values used in the following (e.g. the duration of the preexperiment step should be adjusted between experiments).

```{r}
# find raw data files from myconditions and store them in a dataframe
myfiles <- myconditions %>% 
  # convert the relevant list items to a dataframe
  lapply(function(.l) .l[ - which(names(.l) %in% c("duration", "medium"))] %>% 
           as.data.frame(stringsAsFactors=FALSE) ) %>% 
  do.call(rbind, .) %>% 
  rename(data_path=paths) %>%
  # for each path, find all files matched by the pattern .*\\d+\\.csv (e.g. *20151023.csv)
  group_by(condition, data_path) %>% 
  do((function(.df)
    list.files(.df$data_path, ".*\\d+\\.csv", recursive=TRUE, full.names=TRUE) %>% data.frame(path=., stringsAsFactors=FALSE) )(.))  

# create condition_ts (describing each temporal change of each condition) from myconditions 
condition_ts <- myconditions %>% 
  # convert the relevant list items to a dataframe
  lapply(function(.l) .l[ - which(names(.l) == "paths")] %>% as.data.frame ) %>% 
  do.call(rbind, .) %>% 
  # add useful variables for each condition step
  group_by(condition) %>% 
  mutate(t_start=cumsum(c(0, duration[-(length(duration))])) * 60,
         t_end=cumsum(duration) * 60 - 1e-5,
         m_cycle=value_occurence_index(medium))

# load perl scripts output to dataframes (using parallel lapply)
nc <- min(length(myfiles), length(mycluster)) # this is a dirty hack because multidplyr crashes with less shards than cores
myframes <- myfiles %>% 
  # process exported files on the cluster if required (otherwise return the list of paths)
  ungroup %>% 
  mutate(ppath=process_moma_data(path, .data2preproc=data2preproc, 
                .scripts_path=perl_scripts_path, .qsub_name="MMex_pl", .force=FALSE) ) %>% 
  # load perl scripts output to dataframes (in parallel, using multidplyr)
  partition(condition, path, cluster=mycluster[1:nc] %>%
              cluster_assign_func(parse_frames_stats, compute_genealogy, which_touch_exit, which_to_progeny) %>%
              cluster_assign_obj(dt, dl, vertical_cutoff)) %>%
  # group_by(path) %>% # non-parallel alternative
  do((function(.df){
    parse_frames_stats(.df$ppath) %>% 
      mutate(time_sec=frame*dt*60, length_um=length_pixel*dl,
             discard_start=(time_sec < 2*3600)) %>%
      # remove frames after touching the exit
      group_by(id) %>%
      mutate(discard_top=which_touch_exit(vertical_top, vertical_cutoff)) %>%
      mutate(discard_top=ifelse(discard_start, FALSE, discard_top)) %>% # not in the preexpt step (2h)
      mutate(end_type=ifelse(any(discard_top), 'exit', end_type)) %>% # update end_type to exit for cells which have touched the vertical cutoff
      # remove daughters of cells that touched the exit
      ungroup %>%
      mutate(discard_top=which_to_progeny(discard_top, cid))
  })(.)) %>%
  collect() %>% 
  # append useful variables (per row)
  ungroup %>% 
  extract(path, c("date", "pos", "gl"), ".*(\\d{8})_.*pos(\\d+).*_GL(\\d+).*", remove=FALSE, convert=TRUE) %>%
  mutate_at(vars(date, pos, gl), factor) %>% 
  mutate(cell=paste(date, pos, gl, id, sep='.'),
         vertical_center=(vertical_bottom + vertical_top)/2) %>% 
  # propagate medium info
  group_by(condition) %>% 
  do((function(.df){
    .ts <- filter(condition_ts, condition==unique(.df$condition))
    .idx <- find_unique_interval(.df$time_sec, .ts$t_start, .ts$t_end)
    mutate(.df, medium=.ts$medium[.idx], m_start=.ts$t_start[.idx], m_cycle=.ts$m_cycle[.idx])
  })(.)) %>% 
  # append useful variables (per cell)
  group_by(date, pos, gl, id) %>%
  mutate(start_time=first(time_sec), end_time=last(time_sec),
         b_rank=round(mean(total_cell_in_lane - cell_num_in_lane)))

```


In order to estimate the fluorescence produced by GFP and to convert it to number of molecules, one needs:
- to subtract the autofluorescence (inferred as a linar function of cell length); the appropriate linear coefficient (for a given strain and illumination condition) must be estimate using a non fluorescent strain.
- to apply the GFP conversion factor; for a given fluorescent protein and illumination conditiopn, this factor must be estimated from data where the cells grow and divide after having stopped GFP production, hence "diluting" their total GFP. 

Here we use dummy estimates for these conversions:

```{r}
autofluo_per_um <- 422.8 # for MG1655 with 2sec illumination at 17% intensity with ND4 filter
fp_per_dn <- 1 # dummy placeholder

autofluo_predict <- function(.h) .h * autofluo_per_um
myframes <- myframes %>%
  mutate(fluogfp_amplitude = fluo_amplitude - autofluo_predict(length_um),
         gfp_nb = fluogfp_amplitude * fp_per_dn)

```


It is useful to compute statistics per cell, over the entire cell cycle, e.g. the cell elongation rate:

```{r}
mycells <- filter(myframes, condition!='switch', !discard_top) %>%
  # group_by(date, pos, gl, id, parent_id, genealogy) %>%
  partition(condition, date, pos, gl, id, parent_id, genealogy, cluster=mycluster) %>%
  filter(!any(discard_start), end_type=='div') %>% # full cell cycles only
  filter(n()>4) %>% # at least 4 time points
  do((function(.df) {
    # browser()
    
    .mod_ll_t <- lm( log(length_um)~time_sec, .df)  # use fastLm() for predict
    # .mod_ll_t <- fastLmPure( cbind(1, .df$time_sec), log(.df$length_um) )
    .mod_lg_t <- fastLmPure( cbind(1, .df$time_sec), log(.df$gfp_nb) )
    .mod_l_t <- fastLmPure( cbind(1, .df$time_sec), .df$length_um )
    .mod_g_t <- fastLmPure( cbind(1, .df$time_sec), .df$gfp_nb )
    .mod_g_l <- fastLmPure( cbind(1, .df$length_um), .df$gfp_nb )

    .time_birth <- first(.df$time_sec)
    .time_div <- last(.df$time_sec)
    .logl <- predict(.mod_ll_t, se.fit=TRUE)
    data.frame(npoints=.mod_ll_t$df.residual+1,
               time_birth=.time_birth, time_div=.time_div, 
               cell_num_from_top=mean(.df$cell_num_in_lane),
               cell_num_from_bottom=mean(.df$total_cell_in_lane-.df$cell_num_in_lane), 
               loglength_start=first(.logl$fit), loglength_startse=first(.logl$se.fit), 
               loglength_end=last(.logl$fit), loglength_endse=last(.logl$se.fit), 
               logl_time_slope=.mod_ll_t$coefficients[2], logl_time_slopesd=summary(.mod_ll_t)$coefficients[2,2], 
               # logl_time_slope=.mod_ll_t$coefficients[2], logl_time_slopesd=.mod_ll_t$stderr[2], 
               logl_time_r2=corPearson(.df$time_sec, log(.df$length_um))^2,
               logg_time_slope=.mod_lg_t$coefficients[2], logg_time_slopesd=.mod_lg_t$stderr[2], 
               logg_time_r2=corPearson(.df$time_sec, log(.df$gfp_nb))^2,
               l_time_slope=.mod_l_t$coefficients[2], l_time_slopesd=.mod_l_t$stderr[2], 
               l_time_r2=corPearson(.df$time_sec, .df$length_um)^2,
               g_time_slope=.mod_g_t$coefficients[2], g_time_slopesd=.mod_g_t$stderr[2], 
               g_time_r2=corPearson(.df$time_sec, .df$gfp_nb)^2,
               g_l_slope=.mod_g_l$coefficients[2], g_l_slopesd=.mod_g_l$stderr[2], 
               g_l_r2=corPearson(.df$length_um, log(.df$gfp_nb))^2)
  })(.) ) %>% 
  collect() %>% 
  arrange(condition, date, pos, gl, id)

print(mycells)
```


In order to visually inspect data, one can plot cell traces for length and fluo. 
For a given growth lane, a minimal example looks like:

```{r}
myframes %>% 
  filter((date=='20160318' & pos==0 & gl==2)) %>% 
  filter(!discard_top, vertical_top>vertical_cutoff) %>% 
  mutate(time_sec=time_sec-2*3600) %>% 
  plot_faceted_var_tracks(.var_col='length_um', .show_cellid=TRUE, .log=TRUE) +
  # mask early frames (requires a dummy df!)
  geom_rect(aes(xmin=-Inf, xmax=0, ymin=0, ymax=Inf, group=1), fill='white', alpha=.6, col='transparent', data=data.frame(a=1)) +
  scale_x_hours(4) +
  scale_y_continuous(breaks=2:4, trans='log2') +
  labs(y='length (µm)')

```

The following code shows all traces of the dataset for several variables, one plot per growth lane and per variable, and save these plots as multipage pdfs:

```{r eval=FALSE}
pls <- myframes %>% 
  group_by(condition, date, pos, gl) %>%
  do(pll=(function(.df){
    # browser()
    if (dim(filter(.df, !discard_top))[1] == 0) return(list())
    .cond <- unique(.df$condition)
    .fill <- RColorBrewer::brewer.pal(3, 'Set1')
    .hmin <- max(1.2,  min(filter(.df, !discard_top)$length_um) )
    .hrange <- (max(filter(.df, !discard_top)$length_um)-.hmin) / 2
    .fmin <- min(filter(.df, !discard_top)$gfp_nb)
    .frange <- (max(filter(.df, !discard_top)$gfp_nb)-.fmin) / 2
    
    custom_labels <- function (.str) {
      .labels <- paste('rank:', .str)
      .labels[.labels=='rank: -1'] <- 'all'
      .labels[.labels=='rank: 6'] <- 'rank: >= 6'
      return(.labels)
    }
    
    list(
      # plot of length traces (in log scale)
      l = filter(.df, !discard_top, vertical_top>vertical_cutoff) %>% 
        mutate(time_sec=time_sec-2*3600) %>% 
        plot_faceted_var_tracks(.var_col='length_um', .show_all=TRUE, .show_cellid=TRUE, .log=TRUE, .facet_labeller=custom_labels) +
        # show medium bar
        geom_rect(aes(xmin=t_start - 2*3600, xmax=t_end - 2*3600, ymin=hmin, ymax=hmax, fill=medium, group=1), size=0.2, data=filter(condition_ts, condition==.cond) %>% mutate(b_rank=-1, hmin=.hmin-.25, hmax=.hmin-.1)) +
        geom_vline(aes(xintercept=t_start - 2*3600, group=1), alpha=.2, size=.5, data=filter(condition_ts, condition==.cond)) +
        geom_text(aes(x=t_start+(t_end-t_start)/2 - 2*3600, y=h, label=medium, group=1), col='white', size=2, hjust=0.5, vjust=0,
                  data=filter(condition_ts, condition==.cond) %>% mutate(b_rank=-1, h=.hmin-.2)) +
        scale_fill_manual(values=c('glucose'=.fill[1], 'lactose'=.fill[2]), guide='none') +
        # mask early frames (requires a dummy df!)
        geom_rect(aes(xmin=-Inf, xmax=0, ymin=0, ymax=Inf, group=1), fill='white', alpha=.6, col='transparent', data=data.frame(a=1)) +
        scale_x_hours(4) +
        scale_y_continuous(breaks=2:4, trans='log2') +
        labs(y='length (µm)'), 
      
      # plot of total fluo traces
      ft = filter(.df, !discard_top, vertical_top>vertical_cutoff) %>% 
        mutate(time_sec=time_sec-2*3600) %>% 
        plot_faceted_var_tracks(.var_col='gfp_nb', .show_all=TRUE, .show_cellid=TRUE, .facet_labeller=custom_labels) +
        # show medium bar
        geom_rect(aes(xmin=t_start - 2*3600, xmax=t_end - 2*3600, ymin=fmin, ymax=fmax, fill=medium), size=0.2, data=filter(condition_ts, condition==.cond) %>% mutate(b_rank=-1, fmin=.fmin-.frange/2.5, fmax=.fmin-.frange/5)) +
        geom_vline(aes(xintercept=t_start - 2*3600), alpha=.2, size=.5, data=filter(condition_ts, condition==.cond, t_start>0)) +
        geom_text(aes(x=(t_start+(t_end-t_start)/2 - 2*3600), y=f, label=medium), col='white', size=2, hjust=0.5, vjust=0,
                  data=filter(condition_ts, condition==.cond) %>% mutate(b_rank=-1, f=.fmin-.frange/3)) +
        scale_fill_manual(values=c('glucose'=.fill[1], 'lactose'=.fill[2]), guide='none') +
        # mask early frames (requires a dummy df!)
        geom_rect(aes(xmin=-Inf, xmax=0, ymin=-Inf, ymax=Inf, group=1), fill='white', alpha=.6, col='transparent', data=data.frame(a=1)) +
        scale_x_hours(4) +
        labs(y='total GFP per cell (molecules)'),
      
      # plot of fluo concentration traces
      fc = filter(.df, !discard_top, vertical_top>vertical_cutoff) %>% 
        mutate(time_sec=time_sec-2*3600, gfp_conc=gfp_nb/length_um) %>% 
        plot_faceted_var_tracks(.var_col='gfp_conc', .show_all=TRUE, .show_cellid=TRUE, .facet_labeller=custom_labels) +
        # show medium bar
        geom_rect(aes(xmin=t_start - 2*3600, xmax=t_end - 2*3600, ymin=fmin/2, ymax=fmax/2, fill=medium), size=0.2, data=filter(condition_ts, condition==.cond) %>% mutate(b_rank=-1, fmin=.fmin-.frange/2.5, fmax=.fmin-.frange/5)) +
        geom_vline(aes(xintercept=t_start - 2*3600), alpha=.2, size=.5, data=filter(condition_ts, condition==.cond, t_start>0)) +
        geom_text(aes(x=(t_start+(t_end-t_start)/2-120), y=f/2, label=medium), col='white', size=2, hjust=0.5, vjust=0, 
                  data=filter(condition_ts, condition==.cond) %>% mutate(b_rank=-1, f=.fmin-.frange/3)) +
        scale_fill_manual(values=c('glucose'=.fill[1], 'lactose'=.fill[2]), guide='none') +
        # mask early frames (requires a dummy df!)
        geom_rect(aes(xmin=-Inf, xmax=0, ymin=-Inf, ymax=Inf, group=1), fill='white', alpha=.6, col='transparent', data=data.frame(a=1)) +
        scale_x_hours(4) +
        labs(y='total GFP per cell (molecules)') 
    )
  })(.))

pdf('plots/example_path_length.pdf', width=12, height=10)
for (i in 1:dim(pls)[1]) {
  if ('l' %in% names(pls[[i, 'pll']]))
    plot(pls[[i, 'pll']] [['l']] + 
           labs(title=sprintf("%s  pos:%02d  GL:%02d", pls[[i, "date"]], pls[[i, "pos"]], pls[[i, "gl"]])))
}
dev.off()

pdf('plots/example_path_fluotot.pdf', width=12, height=10)
for (i in 1:dim(pls)[1]) {
  if ('ft' %in% names(pls[[i, 'pll']]))
  plot(pls[[i, 'pll']] [['ft']] + 
         labs(title=sprintf("%s  pos:%02d  GL:%02d", pls[[i, "date"]], pls[[i, "pos"]], pls[[i, "gl"]])))
}
dev.off()

pdf('plots/example_path_fluoconc.pdf', width=12, height=10)
for (i in 1:dim(pls)[1]) {
  if ('fc' %in% names(pls[[i, 'pll']]))
  plot(pls[[i, 'pll']] [['fc']] + 
         labs(title=sprintf("%s  pos:%02d  GL:%02d", pls[[i, "date"]], pls[[i, "pos"]], pls[[i, "gl"]])))
}
dev.off()

```


A trick to save the current environment without the huge `pls` variable:

```{r eval=FALSE}
myvars <- ls(all.names = TRUE)
save(list=myvars[which(myvars!='pls')], file=".RData", envir=.GlobalEnv)

```


