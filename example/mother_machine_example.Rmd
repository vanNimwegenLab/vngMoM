---
title: "Demo script for mother machine data analysed with MoMA"
author: Thomas Julou
output: html_document
---

Setup the working environment:

```{r settings}
# define global settings for knitr
knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE) # , include=FALSE

# set working environment (load all shared R scripts)
setwd("example") # required for `here` to start in the right sub-directory (for this example only)
mylibs <- c('here', 'tidyverse', 'tools', 'RcppArmadillo', 'ccaPP', 'vngMoM', 'ggCustomTJ')
invisible( suppressPackageStartupMessages( # don't use %>% before loading dplyr
  lapply(mylibs, library, character.only=TRUE) ))
library(svglite)

dir.create(here("slogs"), showWarnings=FALSE) # create a directory to store logs from the queue

# set a parallel environment to run multidplyr
library(multidplyr)
mycluster <- min(30, parallel::detectCores()-1) %>%  # do not use more than 30 cores
  new_cluster(.options = callr::r_session_options(user_profile = FALSE)) %>% # disable user profile to avoid endless startup with `renv`
  cluster_library(mylibs)  # load libraries on each core

```


Define general variables:

```{r variables, include=FALSE}
dl <- 0.065         # pixel size (µm)
vertical_cutoff <- 1 / dl   # after it touched this coordinate a cell is discarded 
                    # (4um, NB E. coli is ca. 2um )

# preprocessed data files (produced by perl scripts) are named and saved by applying
# `data2preproc` to their path (e.g. reproduce `data` inner structure inside `preproc`):
data2preproc_dir <- function(.d)
  str_match(.d, '20\\d{6}') %>% na.omit %>% as.character %>% 
  here('preproc', .)
data2preproc_file <- function(.f)
  basename(.f) %>% sub("ExportedCellStats_", "", .) %>% 
  file_path_sans_ext %>% paste0("_frames.txt")
data2preproc <- function(.f)
  file.path(data2preproc_dir(.f), data2preproc_file(.f))

```

Define experimental conditions and the corresponding data (see ReadMe.md):

```{r}
myconditions <- list(
 list(condition='glu_lac_4h', 
        duration=c(360, 240, 240, 240, 240, 240), dt=180, 
        medium=c('glucose', 'lactose', 'glucose', 'lactose', 'glucose', 'lactose'),
        paths=c(here("data", "20150703_pos0")))
)

```

Load all frames in a dataframe:

- This step calls a perl script to analyze MoMA's output (see ReadMe.md). 
  + If all files have already been processed, data will be loaded in a dataframe
  + otherwise, files to be analyze will be submitted to the cluster's queue and an error will be returned; you can check the state of the queue using the function printed in the error message
  + to force the preprocessing to be run again for all files, use .force=TRUE in `process_moma_data`.
- If you use `myconditions` appropriately, you should not need to call this loading step more than once per project.
- The specific values used in the following (e.g. the duration of the preexperiment step should be adjusted between experiments).

```{r}
# find raw data files from myconditions and store them in a dataframe
myfiles <- myconditions %>% 
  # convert the relevant list items to a dataframe
  lapply(function(.l) .l[ - which(names(.l) %in% c("duration", "medium"))] %>% 
           as.data.frame(stringsAsFactors=FALSE) ) %>% 
  do.call(rbind, .) %>% 
  rename(data_path=paths) %>%
  # for each path, find all files matched by the pattern .*\\d+\\.csv (e.g. *20151023.csv)
  group_by(condition, data_path) %>% 
  do((function(.df)
    # list.files(.df$data_path, ".*\\d+\\.csv", recursive=TRUE, full.names=TRUE) %>% 
    find.files(.df$data_path, "ExportedCellStats_*.csv") %>% # faster alternative to list.files (for unix-based OS)
      data.frame(path=., stringsAsFactors=FALSE) )(.))  

#  create condition_acq_times (describing acquisition times and temporal change of each condition) from myconditions
condition_acq_times <- myconditions %>% 
  # convert the relevant list items to a dataframe
  lapply(function(.l) .l[ - which(names(.l) == "paths")] %>% as_tibble ) %>% 
  bind_rows() %>% 
  group_by(condition) %>% 
  mutate(m_start=cumsum(c(0, duration[-(length(duration))])) * 60,
         m_end=cumsum(duration) * 60 - 1e-5, duration=NULL,
         m_cycle=value_occurence_index(medium), 
  ) %>% 
  group_by(condition, m_start) %>% 
  mutate(data=list(data.frame(time_sec=seq(m_start, m_end, dt)) )) %>% unnest(cols=data) %>% 
  group_by(condition) %>% 
  mutate(frame=as.numeric(order(time_sec)-1))

# load perl scripts output to dataframes (using parallel dplyr)
myframes <- myfiles %>% 
  # process exported files on the cluster if required (otherwise return the list of paths)
  ungroup %>% 
  mutate(ppath=process_moma_data(path, .data2preproc=data2preproc, 
                .frames_pl_script="get_size_and_fluo_multich.pl", .qsub_name="MMex_pl", .force=FALSE) ) %>% 
  filter(!is.na(ppath)) %>% 
  # load perl scripts output to dataframes (in parallel, using multidplyr)
  group_by(condition, path) %>%
  partition(mycluster %>% cluster_copy(c("dl", "vertical_cutoff", "condition_acq_times"))) %>%
  do((function(.df){
    # browser()
    # print(.df$ppath)
    parse_frames_stats(.df$ppath)
  })(.)) %>%
  collect() %>%
  ungroup %>%
  extract(path, c("date", "pos", "gl"), ".*(\\d{8})_.*[Pp]os(\\d+).*_GL(\\d+).*", remove=FALSE, convert=TRUE) %>%
  # propagate time and medium info
  left_join(condition_acq_times) %>%
  group_by(path) %>% 
  mutate(m_end=ifelse(m_end > max(time_sec), max(time_sec), m_end)) %>% 
  # fix end_type for pruned cells
  mutate(discard_start=(time_sec < 2*3600), length_um=length_pixel*dl) %>%
  group_by(path) %>%
  mutate(ndgt=compute_daughters_numbers(cid)) %>%
  mutate(end_type_moma=end_type,
         end_type=ifelse(ndgt==0, "lost", "weird"),
         end_type=ifelse(ndgt==2, "div", end_type)) %>%
  # remove frames after touching the exit
  group_by(id, .add=TRUE) %>%
  mutate(discard_top=which_touch_exit(vertical_top, vertical_cutoff)) %>%
  mutate(discard_top=ifelse(discard_start, FALSE, discard_top)) %>% # not in the preexpt step (2h)
  mutate(end_type=ifelse(any(discard_top), 'touchtop', end_type)) %>% # update end_type to exit for cells which have touched the vertical cutoff
  # remove daughters of cells that touched the exit
  group_by(path) %>%
  mutate(discard_top=which_to_progeny(discard_top, cid)) %>%
  # append useful variables (per cell)
  mutate(
    cell=paste(date, pos, gl, id, sep='.'),
    ugen=paste(date, pos, gl, genealogy, sep='.'),
    gl_id=paste(date, pos, gl, sep='.'),
    vertical_center=(vertical_bottom + vertical_top)/2,
    mstep=paste(medium, m_cycle, sep='.'),
  ) %>%
  group_by(date, pos, gl, id) %>%
  mutate(start_time=first(time_sec), end_time=last(time_sec),
         b_rank=round(mean(total_cell_in_lane - cell_num_in_lane)),
         length_um=(vertical_bottom-vertical_top)*dl)

```


In order to estimate the fluorescence produced by GFP and to convert it to number of molecules, one needs:
- to subtract the autofluorescence (inferred as a linar function of cell length); the appropriate linear coefficient (for a given strain and illumination condition) must be estimate using a non fluorescent strain.
- to apply the GFP conversion factor; for a given fluorescent protein and illumination conditiopn, this factor must be estimated from data where the cells grow and divide after having stopped GFP production, hence "diluting" their total GFP. 

Here we use dummy estimates for these conversions:

```{r}
autofluo_per_um <- 422.8 # for MG1655 with 2sec illumination at 17% intensity with ND4 filter
fp_per_dn <- 1 # dummy placeholder

autofluo_predict <- function(.h) .h * autofluo_per_um
myframes <- myframes %>%
  mutate(fluogfp_amplitude = fluo_amplitude - autofluo_predict(length_um),
         gfp_nb = fluogfp_amplitude * fp_per_dn)

```


It is useful to compute statistics per cell, over the entire cell cycle, e.g. the cell elongation rate:

```{r}
mycells <- filter(myframes, !discard_top) %>%
  group_by(condition, date, pos, gl, id, parent_id, genealogy) %>%
  partition(mycluster) %>%
  filter(!any(discard_start), end_type=='div') %>% # full cell cycles only
  filter(n()>4) %>% # at least 4 time points
  do((function(.df) {
    # browser()
    
    .mod_ll_t <- lm( log(length_um)~time_sec, .df)  # use fastLm() for predict
    # .mod_ll_t <- fastLmPure( cbind(1, .df$time_sec), log(.df$length_um) )
    .mod_lg_t <- fastLmPure( cbind(1, .df$time_sec), log(.df$gfp_nb) )
    .mod_l_t <- fastLmPure( cbind(1, .df$time_sec), .df$length_um )
    .mod_g_t <- fastLmPure( cbind(1, .df$time_sec), .df$gfp_nb )
    .mod_g_l <- fastLmPure( cbind(1, .df$length_um), .df$gfp_nb )

    .time_birth <- first(.df$time_sec)
    .time_div <- last(.df$time_sec)
    .logl <- predict(.mod_ll_t, se.fit=TRUE)
    data.frame(npoints=.mod_ll_t$df.residual+1,
               time_birth=.time_birth, time_div=.time_div, 
               cell_num_from_top=mean(.df$cell_num_in_lane),
               cell_num_from_bottom=mean(.df$total_cell_in_lane-.df$cell_num_in_lane), 
               loglength_start=first(.logl$fit), loglength_startse=first(.logl$se.fit), 
               loglength_end=last(.logl$fit), loglength_endse=last(.logl$se.fit), 
               logl_time_slope=.mod_ll_t$coefficients[2], logl_time_slopesd=summary(.mod_ll_t)$coefficients[2,2], 
               # logl_time_slope=.mod_ll_t$coefficients[2], logl_time_slopesd=.mod_ll_t$stderr[2], 
               logl_time_r2=corPearson(.df$time_sec, log(.df$length_um))^2,
               logg_time_slope=.mod_lg_t$coefficients[2], logg_time_slopesd=.mod_lg_t$stderr[2], 
               logg_time_r2=corPearson(.df$time_sec, log(.df$gfp_nb))^2,
               l_time_slope=.mod_l_t$coefficients[2], l_time_slopesd=.mod_l_t$stderr[2], 
               l_time_r2=corPearson(.df$time_sec, .df$length_um)^2,
               g_time_slope=.mod_g_t$coefficients[2], g_time_slopesd=.mod_g_t$stderr[2], 
               g_time_r2=corPearson(.df$time_sec, .df$gfp_nb)^2,
               g_l_slope=.mod_g_l$coefficients[2], g_l_slopesd=.mod_g_l$stderr[2], 
               g_l_r2=corPearson(.df$length_um, log(.df$gfp_nb))^2)
  })(.) ) %>% 
  collect() %>% 
  arrange(condition, date, pos, gl, id)

```


In order to visually inspect data, one can plot cell traces for length and fluo. 
For a given growth lane, a minimal example looks like:

```{r}
myframes %>% 
  group_by(date, pos, gl) %>% 
  nest() %>% ungroup() %>% slice(1L) %>% unnest(data) %>% 
  filter(vertical_top>vertical_cutoff) %>%
  mutate(time_sec=time_sec-2*3600) %>% 
  plot_faceted_var_tracks(.var_col=length_um, .show_cellid=TRUE, .log=TRUE) +
  # mask early frames (requires a dummy df!)
  geom_rect(aes(xmin=-Inf, xmax=0, ymin=0, ymax=Inf, group=1), fill='white', alpha=.6, col='transparent', data=data.frame(a=1)) +
  ggCustomTJ::scale_x_hours(4) +
  scale_y_continuous(breaks=2:4, trans='log2') +
  labs(y='length (µm)')

```

The following code shows all traces of the dataset for several variables, one plot per growth lane and per variable, and save these plots as multipage pdfs:

```{r eval=FALSE}
pls <- myframes %>% 
  group_by(condition, date, pos, gl) %>%
  nest() %>%
  summarise((function(.df, .cond){ 
    # browser()
    .df <- .df[[1]]
    if (dim(filter(.df, !discard_top))[1] == 0) return(tibble())
    .hmin <- max(1.2,  min(filter(.df, !discard_top)$length_um) )
    .hrange <- (max(filter(.df, !discard_top)$length_um)-.hmin) / 2
    .fmin <- min(filter(.df, !discard_top)$gfp_nb)
    .frange <- (max(filter(.df, !discard_top)$gfp_nb)-.fmin) / 2
    
    custom_labels <- function (.str) {
      .labels <- paste('rank:', .str)
      .labels[.labels=='rank: -1'] <- 'all'
      .labels[.labels=='rank: 6'] <- 'rank: >= 6'
      return(.labels)
    }
    
    .out <- tibble( 
      var=c('length_um', 'gfp_nb', 'gfp_conc'),
      pl=list(
        # plot of length traces (in log scale)
        filter(.df, vertical_top>vertical_cutoff) %>% 
          mutate(time_sec=time_sec-2*3600) %>% 
          plot_faceted_var_tracks(.var_col=length_um, .show_all=TRUE, .show_cellid=TRUE, .log=TRUE, .facet_labeller=custom_labels) +
          # show medium bar
          geom_vline(aes(xintercept=m_start - 2*3600, group=1), alpha=.2, size=.5, 
                     data=condition_acq_times %>% group_by(condition, medium, m_cycle) %>% slice(1) %>% 
                       filter(condition==.cond)) +
          geom_rect(aes(xmin=m_start - 2*3600, xmax=m_end - 2*3600, ymin=hmin, ymax=hmax, fill=medium, group=1),
                    show.legend=FALSE, #size=0.2,
                    data=condition_acq_times %>% group_by(condition, medium, m_cycle) %>% slice(1) %>%
                      filter(condition==.cond) %>% mutate(b_rank=-1, hmin=.hmin-.25, hmax=.hmin-.1)) +
          geom_text(aes(x=m_start+(m_end-m_start)/2 - 2*3600, y=h, label=medium, group=1), 
                    size=2, col='white', hjust=0.5, vjust=-0.5, 
                    data=condition_acq_times %>% group_by(condition, medium, m_cycle) %>% slice(1) %>% 
                      filter(condition==.cond) %>% mutate(
                        b_rank=-1, h=.hmin-.2, m_start=ifelse(m_start<2*3600, 2*3600, m_start))) +
          # mask early frames (requires a dummy df!)
          geom_rect(aes(xmin=-Inf, xmax=0, ymin=0, ymax=Inf, group=1), fill='white', alpha=.6, col='transparent', data=data.frame(a=1)) +
          scale_x_hours(4) +
          scale_y_continuous(breaks=2:4, trans='log2') +
          scale_fill_periodic_brewer() +
          labs(y='length (µm)'), 
        
        # plot of total fluo traces
        filter(.df, vertical_top>vertical_cutoff) %>% 
          mutate(time_sec=time_sec-2*3600) %>% 
          plot_faceted_var_tracks(.var_col=gfp_nb, .show_all=TRUE, .show_cellid=TRUE, .facet_labeller=custom_labels) +
          # show medium bar
          geom_vline(aes(xintercept=m_start - 2*3600, group=1), alpha=.2, size=.5, 
                     data=condition_acq_times %>% group_by(condition, medium, m_cycle) %>% slice(1) %>% 
                       filter(condition==.cond)) +
          geom_rect(aes(xmin=m_start - 2*3600, xmax=m_end - 2*3600, ymin=fmin, ymax=fmax, fill=medium, group=1),
                    show.legend=FALSE, #size=0.2,
                    data=condition_acq_times %>% group_by(condition, medium, m_cycle) %>% slice(1) %>%
                      filter(condition==.cond) %>% mutate(b_rank=-1, fmin=.fmin-.frange/2.5, fmax=.fmin-.frange/5)) +
          geom_text(aes(x=m_start+(m_end-m_start)/2 - 2*3600, y=f, label=medium, group=1), 
                    size=2, col='white', hjust=0.5, vjust=-0.5, 
                    data=condition_acq_times %>% group_by(condition, medium, m_cycle) %>% slice(1) %>% 
                      filter(condition==.cond) %>% mutate(
                        b_rank=-1, f=.fmin-.frange/3, m_start=ifelse(m_start<2*3600, 2*3600, m_start))) +
          # mask early frames (requires a dummy df!)
          geom_rect(aes(xmin=-Inf, xmax=0, ymin=-Inf, ymax=Inf, group=1), fill='white', alpha=.6, col='transparent', data=data.frame(a=1)) +
          scale_x_hours(4) +
          scale_fill_periodic_brewer() +
          labs(y='total GFP per cell (AU)'),
        
        # plot of fluo concentration traces
        filter(.df, vertical_top>vertical_cutoff) %>% 
          mutate(time_sec=time_sec-2*3600, gfp_conc=gfp_nb/length_um) %>% 
          plot_faceted_var_tracks(.var_col=gfp_conc, .show_all=TRUE, .show_cellid=TRUE, .facet_labeller=custom_labels) +
          # show medium bar
          geom_vline(aes(xintercept=m_start - 2*3600, group=1), alpha=.2, size=.5, 
                     data=condition_acq_times %>% group_by(condition, medium, m_cycle) %>% slice(1) %>% 
                       filter(condition==.cond)) +
          geom_rect(aes(xmin=m_start - 2*3600, xmax=m_end - 2*3600, ymin=fmin, ymax=fmax, fill=medium, group=1),
                    show.legend=FALSE, #size=0.2,
                    data=condition_acq_times %>% group_by(condition, medium, m_cycle) %>% slice(1) %>%
                      filter(condition==.cond) %>% mutate(b_rank=-1, fmin=.fmin-.frange/2.5, fmax=.fmin-.frange/5)) +
          geom_text(aes(x=m_start+(m_end-m_start)/2 - 2*3600, y=f, label=medium, group=1), 
                    size=2, col='white', hjust=0.5, vjust=-0.5, 
                    data=condition_acq_times %>% group_by(condition, medium, m_cycle) %>% slice(1) %>% 
                      filter(condition==.cond) %>% mutate(
                        b_rank=-1, f=.fmin-.frange/3, m_start=ifelse(m_start<2*3600, 2*3600, m_start))) +
          # mask early frames (requires a dummy df!)
          geom_rect(aes(xmin=-Inf, xmax=0, ymin=-Inf, ymax=Inf, group=1), fill='white', alpha=.6, col='transparent', data=data.frame(a=1)) +
          scale_x_hours(4) +
          scale_fill_periodic_brewer() +
          labs(y='GFP concentration (AU)') 
      ) ) 
})(data, condition))


pls %>% 
  group_by(var) %>% 
  summarise((function(.var){ # unconvincing alternative to do
    # browser() 
    pdf(sprintf('plots/example_path_%s.pdf', cur_group()$var), width=12, height=10)
    cur_data() %>% 
      group_by(condition, date, pos, gl) %>% 
      summarise((function(.x){
        # browser()
        plot(cur_data()$pl[[1]] + 
               labs(title=sprintf("%s  pos:%02d  GL:%02d", cur_group()$date, cur_group()$pos, cur_group()$gl)) )
        return(tibble())
      })(condition))
    dev.off()
    return(tibble())
  })(var)) %>% 
  invisible()

```


A trick to save the current environment without the huge `pls` variable:

```{r eval=FALSE}
myvars <- ls(all.names = TRUE)
save(list=myvars[which(myvars!='pls')], file=".RData", envir=.GlobalEnv)

```


